#!/bin/bash
# Comprehensive CVE Database Scanning Script
# OpenCitiVibes Penetration Testing - Phase 5.5
#
# This script orchestrates comprehensive CVE scanning across:
# - Container images (Trivy, Grype)
# - OS packages
# - Filesystem vulnerabilities
# - Project dependencies (Python/Node.js)
# - NVD database correlation
# - Exploit-DB cross-referencing
# - CVE prioritization and exploitability assessment

source /app/scripts/helpers/colors.sh
print_banner

export SCAN_DIR="${SCAN_DIR:-/app/results/cve/$(date +%Y%m%d_%H%M%S)}"
export SOURCE_DIR="${SOURCE_DIR:-/app/source}"
mkdir -p "${SCAN_DIR}"
mkdir -p "${SCAN_DIR}/containers"
mkdir -p "${SCAN_DIR}/os"
mkdir -p "${SCAN_DIR}/filesystem"
mkdir -p "${SCAN_DIR}/dependencies"
mkdir -p "${SCAN_DIR}/nvd_cache"

log_info "============================================"
log_info "CVE Database Scanning - Phase 5.5"
log_info "============================================"
log_info "Scan directory: ${SCAN_DIR}"
log_info "Source directory: ${SOURCE_DIR}"
echo ""

START_TIME=$(date +%s)

# ============================================================================
# Phase 1: Container Image Scanning
# ============================================================================

phase_container_scanning() {
    log_info "[1/7] Container Image Scanning..."

    # Define project images to scan
    IMAGES=(
        "idees-montreal-backend:latest"
        "idees-montreal-frontend:latest"
        "nginx:alpine"
        "python:3.13-slim"
        "node:20-alpine"
    )

    # Trivy scanning
    if command -v trivy &> /dev/null; then
        log_info "Running Trivy container scans..."
        for IMAGE in "${IMAGES[@]}"; do
            log_info "  Scanning: ${IMAGE}"
            IMAGE_SAFE=$(echo "${IMAGE}" | tr ':/' '__')

            # Check if image exists locally
            if docker image inspect "${IMAGE}" &> /dev/null 2>&1; then
                # JSON output for parsing
                trivy image \
                    --format json \
                    --output "${SCAN_DIR}/containers/trivy-${IMAGE_SAFE}.json" \
                    --severity CRITICAL,HIGH,MEDIUM \
                    --vuln-type os,library \
                    "${IMAGE}" 2>/dev/null || log_warning "Trivy scan failed for ${IMAGE}"

                # Table output for human review
                trivy image \
                    --format table \
                    --severity CRITICAL,HIGH,MEDIUM \
                    "${IMAGE}" 2>&1 | tee "${SCAN_DIR}/containers/trivy-${IMAGE_SAFE}.txt" || true
            else
                log_warning "  Image ${IMAGE} not found locally, skipping"
            fi
        done
    else
        log_warning "Trivy not installed, skipping container scanning"
    fi

    # Grype scanning
    if command -v grype &> /dev/null; then
        log_info "Running Grype container scans..."
        for IMAGE in "${IMAGES[@]}"; do
            IMAGE_SAFE=$(echo "${IMAGE}" | tr ':/' '__')

            if docker image inspect "${IMAGE}" &> /dev/null 2>&1; then
                grype "${IMAGE}" \
                    -o json \
                    --file "${SCAN_DIR}/containers/grype-${IMAGE_SAFE}.json" \
                    2>/dev/null || true

                grype "${IMAGE}" \
                    -o table \
                    2>&1 | tee "${SCAN_DIR}/containers/grype-${IMAGE_SAFE}.txt" || true
            fi
        done
    else
        log_warning "Grype not installed, skipping"
    fi

    log_success "Container scanning complete"
}

# ============================================================================
# Phase 2: OS Package Scanning
# ============================================================================

phase_os_scanning() {
    log_info ""
    log_info "[2/7] OS Package Vulnerability Scanning..."

    # Trivy rootfs scan
    if command -v trivy &> /dev/null; then
        log_info "Scanning root filesystem with Trivy..."
        trivy rootfs \
            --format json \
            --output "${SCAN_DIR}/os/trivy-rootfs.json" \
            --severity CRITICAL,HIGH,MEDIUM \
            / 2>/dev/null || log_warning "Trivy rootfs scan had issues"

        trivy rootfs \
            --format table \
            --severity CRITICAL,HIGH,MEDIUM \
            / 2>&1 | tee "${SCAN_DIR}/os/trivy-rootfs.txt" || true
    fi

    # APT package check (Debian/Kali)
    if command -v apt &> /dev/null; then
        log_info "Checking APT package vulnerabilities..."
        dpkg-query -W -f='${Package}=${Version}\n' > "${SCAN_DIR}/os/installed-packages.txt"
        apt list --upgradable 2>/dev/null | grep -i security > "${SCAN_DIR}/os/security-updates.txt" || true

        # debsecan if available
        if command -v debsecan &> /dev/null; then
            log_info "Running debsecan..."
            debsecan --format detail > "${SCAN_DIR}/os/debsecan.txt" 2>/dev/null || true
        fi
    fi

    # Grype filesystem scan
    if command -v grype &> /dev/null; then
        log_info "Scanning filesystem with Grype..."
        grype dir:/ \
            -o json \
            --file "${SCAN_DIR}/os/grype-rootfs.json" \
            2>/dev/null || true

        grype dir:/ \
            -o table \
            2>&1 | tee "${SCAN_DIR}/os/grype-rootfs.txt" || true
    fi

    log_success "OS package scanning complete"
}

# ============================================================================
# Phase 3: Filesystem Scanning
# ============================================================================

phase_filesystem_scanning() {
    log_info ""
    log_info "[3/7] Filesystem Vulnerability Scanning..."

    if command -v trivy &> /dev/null; then
        log_info "Scanning project source with Trivy..."
        trivy fs \
            --format json \
            --output "${SCAN_DIR}/filesystem/trivy-source.json" \
            --severity CRITICAL,HIGH,MEDIUM \
            --scanners vuln,secret,misconfig \
            "${SOURCE_DIR}" 2>/dev/null || true

        trivy fs \
            --format table \
            --severity CRITICAL,HIGH,MEDIUM \
            "${SOURCE_DIR}" 2>&1 | tee "${SCAN_DIR}/filesystem/trivy-source.txt" || true

        # Generate SBOMs
        log_info "Generating Software Bill of Materials..."
        if [ -f "${SOURCE_DIR}/backend/pyproject.toml" ]; then
            trivy fs \
                --format cyclonedx \
                --output "${SCAN_DIR}/filesystem/sbom-backend.json" \
                "${SOURCE_DIR}/backend" 2>/dev/null || true
        fi

        if [ -f "${SOURCE_DIR}/frontend/package.json" ]; then
            trivy fs \
                --format cyclonedx \
                --output "${SCAN_DIR}/filesystem/sbom-frontend.json" \
                "${SOURCE_DIR}/frontend" 2>/dev/null || true
        fi
    fi

    # Check SUID/SGID binaries
    log_info "Checking for vulnerable binaries..."
    {
        echo "# SUID/SGID Binary Analysis"
        echo "Date: $(date)"
        echo ""
        find / -type f \( -perm -4000 -o -perm -2000 \) 2>/dev/null | head -100 | while read binary; do
            echo "Binary: ${binary}"
            echo "Permissions: $(ls -la "${binary}" 2>/dev/null | awk '{print $1}')"
            "${binary}" --version 2>/dev/null | head -1 || echo "Version: unknown"
            echo ""
        done
    } > "${SCAN_DIR}/filesystem/suid-binaries.txt"

    log_success "Filesystem scanning complete"
}

# ============================================================================
# Phase 4: Project Dependency Scanning
# ============================================================================

phase_dependency_scanning() {
    log_info ""
    log_info "[4/7] Project Dependency Scanning..."

    BACKEND_DIR="${SOURCE_DIR}/backend"
    FRONTEND_DIR="${SOURCE_DIR}/frontend"

    # Python dependencies
    if [ -d "${BACKEND_DIR}" ]; then
        log_info "Scanning Python dependencies..."
        cd "${BACKEND_DIR}"

        # pip-audit
        if command -v pip-audit &> /dev/null; then
            log_info "  Running pip-audit..."
            pip-audit \
                --format json \
                --output "${SCAN_DIR}/dependencies/pip-audit.json" \
                2>/dev/null || true

            pip-audit \
                --format columns \
                2>&1 | tee "${SCAN_DIR}/dependencies/pip-audit.txt" || true
        fi

        # Trivy for Python
        if command -v trivy &> /dev/null; then
            log_info "  Running Trivy on Python dependencies..."
            trivy fs \
                --format json \
                --output "${SCAN_DIR}/dependencies/trivy-python.json" \
                --severity CRITICAL,HIGH,MEDIUM \
                --scanners vuln \
                . 2>/dev/null || true

            trivy fs \
                --format table \
                --severity CRITICAL,HIGH,MEDIUM \
                . 2>&1 | tee "${SCAN_DIR}/dependencies/trivy-python.txt" || true
        fi

        # Grype for Python
        if command -v grype &> /dev/null; then
            log_info "  Running Grype on Python dependencies..."
            grype dir:. \
                -o json \
                --file "${SCAN_DIR}/dependencies/grype-python.json" \
                2>/dev/null || true
        fi

        # safety check
        if command -v safety &> /dev/null; then
            log_info "  Running Safety check..."
            pip freeze > /tmp/requirements.txt 2>/dev/null
            safety check \
                -r /tmp/requirements.txt \
                --json \
                --output "${SCAN_DIR}/dependencies/safety.json" 2>/dev/null || true
        fi

        cd - > /dev/null
    fi

    # Node.js dependencies
    if [ -d "${FRONTEND_DIR}" ]; then
        log_info "Scanning Node.js dependencies..."
        cd "${FRONTEND_DIR}"

        # pnpm audit
        if command -v pnpm &> /dev/null; then
            log_info "  Running pnpm audit..."
            pnpm audit \
                --json > "${SCAN_DIR}/dependencies/pnpm-audit.json" 2>/dev/null || true
            pnpm audit \
                2>&1 | tee "${SCAN_DIR}/dependencies/pnpm-audit.txt" || true
        fi

        # npm audit
        if command -v npm &> /dev/null; then
            log_info "  Running npm audit..."
            npm audit \
                --json > "${SCAN_DIR}/dependencies/npm-audit.json" 2>/dev/null || true
            npm audit \
                2>&1 | tee "${SCAN_DIR}/dependencies/npm-audit.txt" || true
        fi

        # Trivy for Node.js
        if command -v trivy &> /dev/null; then
            log_info "  Running Trivy on Node.js dependencies..."
            trivy fs \
                --format json \
                --output "${SCAN_DIR}/dependencies/trivy-nodejs.json" \
                --severity CRITICAL,HIGH,MEDIUM \
                --scanners vuln \
                . 2>/dev/null || true
        fi

        # Grype for Node.js
        if command -v grype &> /dev/null; then
            log_info "  Running Grype on Node.js dependencies..."
            grype dir:. \
                -o json \
                --file "${SCAN_DIR}/dependencies/grype-nodejs.json" \
                2>/dev/null || true
        fi

        cd - > /dev/null
    fi

    log_success "Project dependency scanning complete"
}

# ============================================================================
# Phase 5: NVD Database Correlation
# ============================================================================

phase_nvd_correlation() {
    log_info ""
    log_info "[5/7] NVD Database Correlation..."

    if [ -f "/app/scripts/cve/nvd_correlate.py" ]; then
        python /app/scripts/cve/nvd_correlate.py 2>&1 | tee "${SCAN_DIR}/nvd-correlation.log"
    else
        log_warning "NVD correlation script not found, running inline..."

        # Inline Python for NVD correlation
        python3 << 'PYTHON_EOF'
import json
import os
import re
import requests
import time
from pathlib import Path
from datetime import datetime

SCAN_DIR = os.environ.get("SCAN_DIR", "/app/results/cve")
NVD_API_URL = "https://services.nvd.nist.gov/rest/json/cves/2.0"

def lookup_cve(cve_id, cache_dir):
    cache_file = cache_dir / f"{cve_id}.json"
    if cache_file.exists():
        with open(cache_file, "r") as f:
            return json.load(f)

    time.sleep(0.6)  # Rate limiting

    try:
        response = requests.get(
            NVD_API_URL,
            params={"cveId": cve_id},
            headers={"Accept": "application/json"},
            timeout=30
        )

        if response.status_code == 200:
            data = response.json()
            if data.get("vulnerabilities"):
                cve_data = data["vulnerabilities"][0]["cve"]
                metrics = cve_data.get("metrics", {})

                cvss = {}
                for version in ["cvssMetricV31", "cvssMetricV30", "cvssMetricV2"]:
                    if version in metrics and metrics[version]:
                        cvss_data = metrics[version][0].get("cvssData", {})
                        cvss = {
                            "score": cvss_data.get("baseScore", 0),
                            "severity": cvss_data.get("baseSeverity", ""),
                            "vector": cvss_data.get("vectorString", "")
                        }
                        break

                result = {
                    "id": cve_id,
                    "cvss": cvss,
                    "nvd_url": f"https://nvd.nist.gov/vuln/detail/{cve_id}"
                }

                with open(cache_file, "w") as f:
                    json.dump(result, f)

                return result

    except Exception as e:
        print(f"Error looking up {cve_id}: {e}")

    return None

def extract_cves_from_trivy(json_file):
    cves = []
    try:
        with open(json_file, "r") as f:
            data = json.load(f)
        for result in data.get("Results", []):
            for vuln in result.get("Vulnerabilities", []):
                cve_id = vuln.get("VulnerabilityID", "")
                if cve_id.startswith("CVE-"):
                    cves.append(cve_id)
    except Exception:
        pass
    return list(set(cves))

def extract_cves_from_grype(json_file):
    cves = []
    try:
        with open(json_file, "r") as f:
            data = json.load(f)
        for match in data.get("matches", []):
            cve_id = match.get("vulnerability", {}).get("id", "")
            if cve_id.startswith("CVE-"):
                cves.append(cve_id)
    except Exception:
        pass
    return list(set(cves))

scan_dir = Path(SCAN_DIR)
cache_dir = scan_dir / "nvd_cache"
cache_dir.mkdir(parents=True, exist_ok=True)

all_cves = set()

print("[*] Collecting CVEs from scan results...")
for trivy_file in scan_dir.glob("**/trivy-*.json"):
    cves = extract_cves_from_trivy(trivy_file)
    all_cves.update(cves)
    print(f"    {trivy_file.name}: {len(cves)} CVEs")

for grype_file in scan_dir.glob("**/grype-*.json"):
    cves = extract_cves_from_grype(grype_file)
    all_cves.update(cves)
    print(f"    {grype_file.name}: {len(cves)} CVEs")

print(f"\n[*] Total unique CVEs: {len(all_cves)}")
print("[*] Looking up CVE details from NVD...")

enriched = []
for i, cve_id in enumerate(sorted(all_cves)):
    print(f"    [{i+1}/{len(all_cves)}] {cve_id}")
    cve_data = lookup_cve(cve_id, cache_dir)
    if cve_data:
        enriched.append(cve_data)

enriched.sort(key=lambda x: x.get("cvss", {}).get("score", 0), reverse=True)

result = {
    "correlation_date": datetime.now().isoformat(),
    "total_cves": len(enriched),
    "by_severity": {
        "CRITICAL": len([c for c in enriched if c.get("cvss", {}).get("score", 0) >= 9.0]),
        "HIGH": len([c for c in enriched if 7.0 <= c.get("cvss", {}).get("score", 0) < 9.0]),
        "MEDIUM": len([c for c in enriched if 4.0 <= c.get("cvss", {}).get("score", 0) < 7.0]),
        "LOW": len([c for c in enriched if 0 < c.get("cvss", {}).get("score", 0) < 4.0])
    },
    "cves": enriched
}

output_file = scan_dir / "nvd_correlation.json"
with open(output_file, "w") as f:
    json.dump(result, f, indent=2)

print(f"\n[+] NVD correlation complete!")
print(f"    Total CVEs: {result['total_cves']}")
print(f"    Critical: {result['by_severity']['CRITICAL']}")
print(f"    High: {result['by_severity']['HIGH']}")
PYTHON_EOF
    fi

    log_success "NVD correlation complete"
}

# ============================================================================
# Phase 6: Exploit-DB Cross-Reference
# ============================================================================

phase_exploitdb_check() {
    log_info ""
    log_info "[6/7] Exploit-DB Cross-Reference..."

    if [ -f "/app/scripts/cve/exploitdb_check.py" ]; then
        python /app/scripts/cve/exploitdb_check.py 2>&1 | tee "${SCAN_DIR}/exploitdb.log"
    elif command -v searchsploit &> /dev/null; then
        log_info "Running searchsploit checks..."

        # Get CVEs from NVD correlation
        if [ -f "${SCAN_DIR}/nvd_correlation.json" ]; then
            CVES=$(jq -r '.cves[].id' "${SCAN_DIR}/nvd_correlation.json" 2>/dev/null)

            EXPLOITABLE=0
            {
                echo "# Exploit-DB Cross-Reference Results"
                echo "Date: $(date)"
                echo ""

                for CVE in ${CVES}; do
                    RESULT=$(searchsploit --cve "${CVE}" 2>/dev/null)
                    if [ -n "${RESULT}" ] && ! echo "${RESULT}" | grep -q "No Results"; then
                        echo "## ${CVE}"
                        echo "\`\`\`"
                        echo "${RESULT}"
                        echo "\`\`\`"
                        echo ""
                        EXPLOITABLE=$((EXPLOITABLE + 1))
                    fi
                done

                echo ""
                echo "## Summary"
                echo "- CVEs with known exploits: ${EXPLOITABLE}"
            } > "${SCAN_DIR}/EXPLOITABILITY_REPORT.md"

            echo "{\"exploitable_cves\": ${EXPLOITABLE}}" > "${SCAN_DIR}/exploitdb_results.json"
        fi
    else
        log_warning "searchsploit not installed, skipping Exploit-DB check"
    fi

    log_success "Exploit-DB check complete"
}

# ============================================================================
# Phase 7: CVE Prioritization
# ============================================================================

phase_prioritization() {
    log_info ""
    log_info "[7/7] CVE Prioritization..."

    if [ -f "/app/scripts/cve/prioritize_cves.py" ]; then
        python /app/scripts/cve/prioritize_cves.py 2>&1 | tee "${SCAN_DIR}/prioritization.log"
    else
        log_info "Running inline prioritization..."

        # Inline Python for prioritization
        python3 << 'PYTHON_EOF'
import json
import os
from pathlib import Path
from datetime import datetime

SCAN_DIR = os.environ.get("SCAN_DIR", "/app/results/cve")
scan_dir = Path(SCAN_DIR)

# Load NVD data
nvd_data = {}
nvd_file = scan_dir / "nvd_correlation.json"
if nvd_file.exists():
    with open(nvd_file, "r") as f:
        data = json.load(f)
        for cve in data.get("cves", []):
            nvd_data[cve["id"]] = cve

# Load exploit data
exploitable = set()
exploit_file = scan_dir / "exploitdb_results.json"
if exploit_file.exists():
    try:
        with open(exploit_file, "r") as f:
            data = json.load(f)
            exploitable = set(data.get("exploitable_cve_list", []))
    except:
        pass

# Collect packages from scans
packages = []
for trivy_file in scan_dir.glob("**/trivy-*.json"):
    try:
        with open(trivy_file, "r") as f:
            data = json.load(f)
        for result in data.get("Results", []):
            for vuln in result.get("Vulnerabilities", []):
                packages.append({
                    "cve_id": vuln.get("VulnerabilityID", ""),
                    "package": vuln.get("PkgName", ""),
                    "fixed_version": vuln.get("FixedVersion", "")
                })
    except:
        pass

# Prioritize
all_cves = set(nvd_data.keys())
all_cves.update([p["cve_id"] for p in packages if p["cve_id"].startswith("CVE-")])

prioritized = []
for cve_id in sorted(all_cves):
    nvd = nvd_data.get(cve_id, {})
    cvss = nvd.get("cvss", {})
    cvss_score = cvss.get("score", 0)

    has_exploit = cve_id in exploitable
    affected = [p for p in packages if p["cve_id"] == cve_id]
    is_fixable = any(p["fixed_version"] for p in affected)

    # Calculate priority score
    priority_score = cvss_score * 10
    if has_exploit:
        priority_score += 20
    priority_score += min(10, len(affected) * 2)
    if not is_fixable:
        priority_score -= 5
    priority_score = min(100, priority_score)

    # Determine tier
    if priority_score >= 85 or (cvss_score >= 9.0 and has_exploit):
        tier = "CRITICAL"
    elif priority_score >= 70 or cvss_score >= 7.0:
        tier = "HIGH"
    elif priority_score >= 50 or cvss_score >= 4.0:
        tier = "MEDIUM"
    else:
        tier = "LOW"

    prioritized.append({
        "cve_id": cve_id,
        "priority_score": round(priority_score, 1),
        "priority_tier": tier,
        "cvss_score": cvss_score,
        "has_exploit": has_exploit,
        "affected_packages": list(set([p["package"] for p in affected])),
        "is_fixable": is_fixable
    })

prioritized.sort(key=lambda x: x["priority_score"], reverse=True)

result = {
    "prioritization_date": datetime.now().isoformat(),
    "total_cves": len(prioritized),
    "by_tier": {
        "CRITICAL": len([p for p in prioritized if p["priority_tier"] == "CRITICAL"]),
        "HIGH": len([p for p in prioritized if p["priority_tier"] == "HIGH"]),
        "MEDIUM": len([p for p in prioritized if p["priority_tier"] == "MEDIUM"]),
        "LOW": len([p for p in prioritized if p["priority_tier"] == "LOW"])
    },
    "exploitable_count": len([p for p in prioritized if p["has_exploit"]]),
    "fixable_count": len([p for p in prioritized if p["is_fixable"]]),
    "prioritized_cves": prioritized
}

output_file = scan_dir / "prioritized_cves.json"
with open(output_file, "w") as f:
    json.dump(result, f, indent=2)

# Generate remediation plan
report = f"""# CVE Remediation Prioritization Plan

**Generated:** {result['prioritization_date']}

## Executive Summary

| Metric | Count |
|--------|-------|
| Total CVEs | {result['total_cves']} |
| Critical Priority | {result['by_tier']['CRITICAL']} |
| High Priority | {result['by_tier']['HIGH']} |
| Medium Priority | {result['by_tier']['MEDIUM']} |
| Low Priority | {result['by_tier']['LOW']} |
| Have Known Exploits | {result['exploitable_count']} |
| Have Available Fixes | {result['fixable_count']} |

## Critical Priority CVEs

These require immediate attention:

"""

critical = [c for c in prioritized if c['priority_tier'] == 'CRITICAL'][:10]
for cve in critical:
    report += f"""
### {cve['cve_id']} (Score: {cve['priority_score']})
- CVSS: {cve['cvss_score']}
- Exploit Available: {'Yes' if cve['has_exploit'] else 'No'}
- Affected Packages: {', '.join(cve['affected_packages'][:5])}
- Fixable: {'Yes' if cve['is_fixable'] else 'No'}
"""

report += """
## Recommended Actions

1. **Immediate**: Address Critical priority CVEs
2. **Short-term**: Schedule High priority CVEs for next sprint
3. **Ongoing**: Monitor for new CVEs in dependencies
"""

report_file = scan_dir / "REMEDIATION_PLAN.md"
with open(report_file, "w") as f:
    f.write(report)

print(f"\n[+] CVE Prioritization complete!")
print(f"    Critical: {result['by_tier']['CRITICAL']}")
print(f"    High: {result['by_tier']['HIGH']}")
print(f"    Medium: {result['by_tier']['MEDIUM']}")
print(f"    Low: {result['by_tier']['LOW']}")
PYTHON_EOF
    fi

    log_success "CVE prioritization complete"
}

# ============================================================================
# Generate Summary Report
# ============================================================================

generate_summary() {
    END_TIME=$(date +%s)
    DURATION=$((END_TIME - START_TIME))

    {
        echo "# CVE Database Scan Summary"
        echo ""
        echo "**Date:** $(date)"
        echo "**Duration:** ${DURATION} seconds"
        echo "**Scan Directory:** ${SCAN_DIR}"
        echo ""
        echo "---"
        echo ""
        echo "## Scan Results"
        echo ""

        # Count findings from scan files
        TRIVY_CRIT=$(cat "${SCAN_DIR}"/containers/trivy-*.txt 2>/dev/null | grep -c "CRITICAL" || echo 0)
        TRIVY_HIGH=$(cat "${SCAN_DIR}"/containers/trivy-*.txt 2>/dev/null | grep -c "HIGH" || echo 0)
        GRYPE_CRIT=$(cat "${SCAN_DIR}"/containers/grype-*.txt 2>/dev/null | grep -c "Critical" || echo 0)
        GRYPE_HIGH=$(cat "${SCAN_DIR}"/containers/grype-*.txt 2>/dev/null | grep -c "High" || echo 0)

        echo "### Container Scanning"
        echo ""
        echo "| Scanner | Critical | High |"
        echo "|---------|----------|------|"
        echo "| Trivy   | ${TRIVY_CRIT} | ${TRIVY_HIGH} |"
        echo "| Grype   | ${GRYPE_CRIT} | ${GRYPE_HIGH} |"
        echo ""

        echo "### CVE Correlation"
        echo ""
        if [ -f "${SCAN_DIR}/nvd_correlation.json" ]; then
            NVD_TOTAL=$(jq '.total_cves' "${SCAN_DIR}/nvd_correlation.json" 2>/dev/null || echo 0)
            NVD_CRIT=$(jq '.by_severity.CRITICAL' "${SCAN_DIR}/nvd_correlation.json" 2>/dev/null || echo 0)
            NVD_HIGH=$(jq '.by_severity.HIGH' "${SCAN_DIR}/nvd_correlation.json" 2>/dev/null || echo 0)
            echo "- Total CVEs correlated with NVD: ${NVD_TOTAL}"
            echo "- Critical (CVSS >= 9.0): ${NVD_CRIT}"
            echo "- High (CVSS >= 7.0): ${NVD_HIGH}"
        else
            echo "- NVD correlation not available"
        fi
        echo ""

        echo "### Exploitability Assessment"
        echo ""
        if [ -f "${SCAN_DIR}/exploitdb_results.json" ]; then
            EXPLOIT_COUNT=$(jq '.exploitable_cves // 0' "${SCAN_DIR}/exploitdb_results.json" 2>/dev/null || echo 0)
            echo "- CVEs with known exploits: ${EXPLOIT_COUNT}"
        else
            echo "- Exploit-DB check not performed"
        fi
        echo ""

        echo "### Prioritization"
        echo ""
        if [ -f "${SCAN_DIR}/prioritized_cves.json" ]; then
            PRIO_CRIT=$(jq '.by_tier.CRITICAL' "${SCAN_DIR}/prioritized_cves.json" 2>/dev/null || echo 0)
            PRIO_HIGH=$(jq '.by_tier.HIGH' "${SCAN_DIR}/prioritized_cves.json" 2>/dev/null || echo 0)
            PRIO_MED=$(jq '.by_tier.MEDIUM' "${SCAN_DIR}/prioritized_cves.json" 2>/dev/null || echo 0)
            PRIO_LOW=$(jq '.by_tier.LOW' "${SCAN_DIR}/prioritized_cves.json" 2>/dev/null || echo 0)
            FIXABLE=$(jq '.fixable_count' "${SCAN_DIR}/prioritized_cves.json" 2>/dev/null || echo 0)

            echo "| Priority | Count |"
            echo "|----------|-------|"
            echo "| Critical | ${PRIO_CRIT} |"
            echo "| High     | ${PRIO_HIGH} |"
            echo "| Medium   | ${PRIO_MED} |"
            echo "| Low      | ${PRIO_LOW} |"
            echo ""
            echo "- Fixable CVEs: ${FIXABLE}"
        else
            echo "- Prioritization not available"
        fi
        echo ""

        echo "---"
        echo ""
        echo "## Generated Reports"
        echo ""
        echo "| Report | Path |"
        echo "|--------|------|"
        [ -f "${SCAN_DIR}/nvd_correlation.json" ] && echo "| NVD Correlation | \`nvd_correlation.json\` |"
        [ -f "${SCAN_DIR}/EXPLOITABILITY_REPORT.md" ] && echo "| Exploitability Report | \`EXPLOITABILITY_REPORT.md\` |"
        [ -f "${SCAN_DIR}/prioritized_cves.json" ] && echo "| Prioritized CVEs | \`prioritized_cves.json\` |"
        [ -f "${SCAN_DIR}/REMEDIATION_PLAN.md" ] && echo "| Remediation Plan | \`REMEDIATION_PLAN.md\` |"
        echo ""

        echo "## Next Steps"
        echo ""
        echo "1. Review \`REMEDIATION_PLAN.md\` for prioritized actions"
        echo "2. Address Critical priority CVEs immediately"
        echo "3. Schedule High priority CVEs for next sprint"
        echo "4. Proceed to Phase 6 for comprehensive reporting"

    } > "${SCAN_DIR}/CVE_SCAN_SUMMARY.md"

    cat "${SCAN_DIR}/CVE_SCAN_SUMMARY.md"
}

# ============================================================================
# Main Execution
# ============================================================================

# Run all phases
phase_container_scanning
phase_os_scanning
phase_filesystem_scanning
phase_dependency_scanning
phase_nvd_correlation
phase_exploitdb_check
phase_prioritization

# Generate summary
generate_summary

log_success ""
log_success "============================================"
log_success "CVE Database Scanning Complete!"
log_success "============================================"
log_info "Duration: $(($(date +%s) - START_TIME)) seconds"
log_info "Results: ${SCAN_DIR}/"
log_info ""
log_info "Key reports:"
log_info "  - Summary: ${SCAN_DIR}/CVE_SCAN_SUMMARY.md"
[ -f "${SCAN_DIR}/REMEDIATION_PLAN.md" ] && log_info "  - Remediation Plan: ${SCAN_DIR}/REMEDIATION_PLAN.md"
[ -f "${SCAN_DIR}/EXPLOITABILITY_REPORT.md" ] && log_info "  - Exploitability: ${SCAN_DIR}/EXPLOITABILITY_REPORT.md"
