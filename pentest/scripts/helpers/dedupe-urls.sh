#!/bin/bash
# URL Deduplication and Normalization Helper
# Removes duplicates, tracking params, and limits total URLs
# OpenCitiVibes Penetration Testing - Phase 3

INPUT_FILE="${1:-/dev/stdin}"
OUTPUT_FILE="${2:-/dev/stdout}"
MAX_URLS="${3:-500}"

# Normalize URLs: remove tracking params, fragments, trailing slashes
normalize_url() {
    echo "$1" | \
        # Remove common tracking params
        sed -E 's/[?&](utm_[^&]*|fbclid|gclid|ref|source|campaign|mc_[^&]*|_ga[^&]*)=[^&]*//g' | \
        # Clean up leftover ? or &
        sed -E 's/[?&]$//g' | \
        sed -E 's/\?&/?/g' | \
        sed -E 's/&&/\&/g' | \
        # Remove fragments
        sed 's/#.*$//' | \
        # Remove trailing slashes (except for root)
        sed -E 's|([^/])/$|\1|' | \
        # Remove empty query strings
        sed 's/?$//'
}

# Process input
if [ -f "${INPUT_FILE}" ]; then
    while IFS= read -r url; do
        normalize_url "$url"
    done < "${INPUT_FILE}"
else
    while IFS= read -r url; do
        normalize_url "$url"
    done
fi | \
    # Remove empty lines
    grep -v '^$' | \
    # Sort and dedupe
    sort -u | \
    # Filter out common non-page URLs
    grep -v -E '\.(css|js|png|jpg|jpeg|gif|svg|ico|woff|woff2|ttf|eot)(\?|$)' | \
    # Limit to max URLs
    head -n "${MAX_URLS}" > "${OUTPUT_FILE}"

# Report results
if [ -f "${OUTPUT_FILE}" ] && [ "${OUTPUT_FILE}" != "/dev/stdout" ]; then
    RESULT_COUNT=$(wc -l < "${OUTPUT_FILE}")
    echo "Normalized ${RESULT_COUNT} unique URLs (max: ${MAX_URLS})" >&2
fi
